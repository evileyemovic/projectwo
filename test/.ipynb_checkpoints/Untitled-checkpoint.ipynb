{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ec584c-cf1f-408e-9100-26bb6cfbf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import rlcard\n",
    "from rlcard.agents.dqn_agent import DQNAgent\n",
    "from rlcard.agents.cfr_agent import CFRAgent\n",
    "from rlcard.agents.random_agent import RandomAgent\n",
    "from rlcard.utils import (\n",
    "    get_device,\n",
    "    set_seed,\n",
    "    tournament,\n",
    "    reorganize,\n",
    "    Logger,\n",
    "    plot_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692e5f74-4175-46a1-8281-62c115c13e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d0e80-fae8-4c93-8015-cd9053867d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "set_seed(42)\n",
    "\n",
    "# No-Limit Hold'em 환경 생성\n",
    "env = rlcard.make('no-limit-holdem', config={'allow_step_back' : True, 'seed' : 42})\n",
    "\n",
    "print(env.num_actions)\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "cfr_agent = CFRAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa082a8-7b40-4e03-b8ff-76679bb27b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "--> Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "env.set_agents([cfr_agent, cfr_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b403c051-503f-477f-9928-a9213b067962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CFR Agent...\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining CFR Agent...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):  \u001b[38;5;66;03m# 100번 반복 학습\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mcfr_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCFR Agent Training Complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\agents\\cfr_agent.py:42\u001b[0m, in \u001b[0;36mCFRAgent.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     41\u001b[0m     probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_players)\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Update policy\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_policy()\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\agents\\cfr_agent.py:75\u001b[0m, in \u001b[0;36mCFRAgent.traverse_tree\u001b[1;34m(self, probs, player_id)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Keep traversing the child state\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 75\u001b[0m utility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep_back()\n\u001b[0;32m     78\u001b[0m state_utility \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m action_prob \u001b[38;5;241m*\u001b[39m utility\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\agents\\cfr_agent.py:75\u001b[0m, in \u001b[0;36mCFRAgent.traverse_tree\u001b[1;34m(self, probs, player_id)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Keep traversing the child state\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 75\u001b[0m utility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep_back()\n\u001b[0;32m     78\u001b[0m state_utility \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m action_prob \u001b[38;5;241m*\u001b[39m utility\n",
      "    \u001b[1;31m[... skipping similar frames: CFRAgent.traverse_tree at line 75 (47 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\agents\\cfr_agent.py:75\u001b[0m, in \u001b[0;36mCFRAgent.traverse_tree\u001b[1;34m(self, probs, player_id)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Keep traversing the child state\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 75\u001b[0m utility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep_back()\n\u001b[0;32m     78\u001b[0m state_utility \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m action_prob \u001b[38;5;241m*\u001b[39m utility\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\agents\\cfr_agent.py:74\u001b[0m, in \u001b[0;36mCFRAgent.traverse_tree\u001b[1;34m(self, probs, player_id)\u001b[0m\n\u001b[0;32m     71\u001b[0m new_probs[current_player] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m action_prob\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Keep traversing the child state\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m utility \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraverse_tree(new_probs, player_id)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep_back()\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\envs\\env.py:86\u001b[0m, in \u001b[0;36mEnv.step\u001b[1;34m(self, action, raw_action)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_recorder\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_player_id(), action))\n\u001b[0;32m     84\u001b[0m next_state, player_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m, player_id\n",
      "File \u001b[1;32mc:\\path\\to\\test1\\rlcard\\rlcard\\envs\\nolimitholdem.py:68\u001b[0m, in \u001b[0;36mNolimitholdemEnv._extract_state\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     66\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard2index[card] \u001b[38;5;28;01mfor\u001b[39;00m card \u001b[38;5;129;01min\u001b[39;00m cards]\n\u001b[0;32m     67\u001b[0m obs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m54\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m obs[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     69\u001b[0m obs[\u001b[38;5;241m52\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(my_chips)\n\u001b[0;32m     70\u001b[0m obs[\u001b[38;5;241m53\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mmax\u001b[39m(all_chips))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training CFR Agent...\")\n",
    "for _ in range(100):  # 100번 반복 학습\n",
    "    cfr_agent.train()\n",
    "\n",
    "print(\"CFR Agent Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89196083-762a-4bb0-ba6a-ab1ecf463331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Training CFR Agent...\")\\nfor _ in range(100):  # 100번 반복 학습\\n    cfr_agent.train()\\n\\nprint(\"CFR Agent Training Complete!\")\\n\\nenv.set_agents([None, cfr_agent])\\n\\n\\n\\n\\n\\nprint(\"Starting game against CFR Agent...\")\\nstate, player_id = env.reset()\\n\\nwhile not env.is_over():\\n    if player_id == 0:  # 사용자의 턴\\n        print(\"\\nYour turn:\")\\n        print(f\"Your state: {state}\")\\n        print(f\"Legal actions: {state[\\'legal_actions\\']}\")\\n        \\n        # 사용자로부터 행동 입력받기\\n        try:\\n            user_action = int(input(\"Choose your action: \"))\\n            if user_action not in state[\\'legal_actions\\']:\\n                raise ValueError\\n        except ValueError:\\n            print(\"Invalid action. Please choose from the legal actions.\")\\n            continue\\n    else:  # CFR 에이전트의 턴\\n        user_action = cfr_agent.step(state)\\n        print(f\"CFR Agent chose action: {user_action}\")\\n\\n    # 행동 수행\\n    state, player_id = env.step(user_action)\\n\\n# 결과 출력\\nprint(\"\\nGame Over!\")\\npayoffs = env.get_payoffs()\\nif payoffs[0] > payoffs[1]:\\n    print(f\"You win! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\\nelif payoffs[0] < payoffs[1]:\\n    print(f\"You lose! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\\nelse:\\n    print(f\"It\\'s a draw! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.set_agents([None, cfr_agent])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Starting game against CFR Agent...\")\n",
    "state, player_id = env.reset()\n",
    "\n",
    "while not env.is_over():\n",
    "    if player_id == 0:  # 사용자의 턴\n",
    "        print(\"\\nYour turn:\")\n",
    "        print(f\"Your state: {state}\")\n",
    "        print(f\"Legal actions: {state['legal_actions']}\")\n",
    "        \n",
    "        # 사용자로부터 행동 입력받기\n",
    "        try:\n",
    "            user_action = int(input(\"Choose your action: \"))\n",
    "            if user_action not in state['legal_actions']:\n",
    "                raise ValueError\n",
    "        except ValueError:\n",
    "            print(\"Invalid action. Please choose from the legal actions.\")\n",
    "            continue\n",
    "    else:  # CFR 에이전트의 턴\n",
    "        user_action = cfr_agent.step(state)\n",
    "        print(f\"CFR Agent chose action: {user_action}\")\n",
    "\n",
    "    # 행동 수행\n",
    "    state, player_id = env.step(user_action)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nGame Over!\")\n",
    "payoffs = env.get_payoffs()\n",
    "if payoffs[0] > payoffs[1]:\n",
    "    print(f\"You win! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\n",
    "elif payoffs[0] < payoffs[1]:\n",
    "    print(f\"You lose! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\n",
    "else:\n",
    "    print(f\"It's a draw! Your payoff: {payoffs[0]}, CFR Agent payoff: {payoffs[1]}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af985c-3adb-4480-baed-8d99ac9fae3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
